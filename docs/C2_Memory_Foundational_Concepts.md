# Chapter 2: Memory Foundational Concepts

Starting to feel worn out from theory? Good, because this chapter is the most theory-heavy one yet. I know, I know, you’re eager to dive into code. Honestly, I debated putting this chapter later in the docs, but it makes more sense to establish these foundations before moving forward. The good news? This will be the last theory-dense chapter (at least for now). The better news? If there’s one chapter you really shouldn’t skip, it’s this one.

In the last chapter, we covered the importance of having a solid build pipeline for our kernel, along with how to structure the project. With that foundation in place, we can now shift our focus to kernel development without extra distractions.

In this chapter, we’ll dive into Virtual and Physical Memory, Paging, the Higher Half Kernel design, and a few other essential concepts. These are just as important as the build system — we need to understand them early on so we can structure the project correctly from the start. 

The last thing we want is to set everything up in a way that forces a complete rewrite later (I'm looking at you, [u/BillyZeim](https://github.com/Billyzeim/)).

## What is Physical Memory?

When we talk about *physical memory*, we are referring to the actual hardware component of a computer system used for temporary data storage: **Random Access Memory (RAM)**. These are the physical chips installed on the motherboard or memory modules (DIMMs) that store data and machine code currently being used by the CPU.

### Characteristics of Physical Memory:

1. **Hardware-Based:** It is a tangible resource with a finite capacity (e.g., 4 GB, 16 GB, 64 GB). Once all physical memory is occupied, the system must resort to other mechanisms, like swapping, which are significantly slower.
2. **Direct CPU Access:** The CPU can read from and write to physical memory addresses directly via the memory bus. This is the fastest form of storage available to the CPU, aside from its internal caches (L1, L2, L3).
3. **Volatile:** The contents of physical memory are lost when the system loses power.
4. **Flat Address Space:** Physical memory is organized as a contiguous, linear array of bytes. Each byte has a unique physical address, starting from `0` and extending to the top of the installed RAM.

### How it Works:

When a program runs, the CPU needs to fetch instructions and data. It does this by issuing requests for specific memory addresses. In a simple system without memory management, the address generated by the CPU (a *physical address*) is sent directly over the address bus to the RAM controller, which then accesses the corresponding location.

For example, if the CPU instructs, "read the byte at address `0x1000`," the memory controller will physically access the 4096th byte (since `0x1000` is 4096 in decimal) in the RAM chips.

>[!IMPORTANT]
>This is a simplified explanation. In reality, modern systems are more complex:
>* **Caching:** The CPU first checks its high-speed caches. If the data is found there (a cache hit), it avoids a slower access to main physical memory.
>* **Memory Management Unit (MMU):** The CPU does not output physical addresses directly. Instead, it outputs *virtual addresses**. A hardware component called the MMU translates these virtual addresses into physical addresses on-the-fly. This is the foundation of modern memory management.
>* **Burst Transfers:** Modern memory systems transfer data in blocks (bursts) rather than single bytes for efficiency.
>
> **We will talk about virtual addresses in depth later on in this document.*

Physical memory is the fundamental pool of fast storage, but using it directly for every running program is inefficient and insecure. This led to the development of memory management schemes, starting with **Segmentation**.

## What is Segmentation?

Segmentation was an early memory management technique that provided a way to isolate processes and organize memory in a logical way. Instead of viewing memory as a single, flat array, segmentation divides it into variable-sized blocks called **segments**.

### The Core Concept:

Each segment is designed to hold a logical unit of a program, such as:

| Segment Type               | Purpose                                                           | Typical Contents                              |
| -------------------------- | ----------------------------------------------------------------- | --------------------------------------------- |
| Code Segment **(.text)**   | Stores executable instructions                                    | Program instructions                          |
| Data Segment **(.data)**   | Stores initialized global and static variables                    | Global/static data                            |
| Stack Segment **(.stack)** | Stores the function call stack, local variables, return addresses | Call stack, local variables, return addresses |
| Heap Segment **(.heap)**   | Stores dynamically allocated memory                               | Memory allocated via `malloc` or similar      |


### How Segmentation Works:

1.  **Segment Registers:** The CPU contains special registers (e.g., `CS` for Code Segment, `DS` for Data Segment, `SS` for Stack Segment) that hold the **base address** (the starting location) of a segment in physical memory.
2.  **Logical Addressing:** A program's address (a *logical address*) is composed of two parts: a **segment selector** and an **offset**.
    *   `Logical Address = <Segment Selector, Offset>`
3.  **Translation to Physical Address:** The CPU translates the logical address into a physical address by taking the segment's base address and adding the offset.
    *   `Physical Address = Segment Base Address + Offset`

For example, if the Code Segment register (`CS`) points to base address `0x4000` and the instruction pointer (`IP`) is at offset `0x0100`, the CPU accesses physical address `0x4000 + 0x0100 = 0x4100`. 

In practice, segmentation is implemented through the [Global Descriptor Table (GDT)](#the-global-descriptor-table-gdt).

### Advantages and Drawbacks

While this was the prevalent memory management scheme for a while, it had many drawbacks. Here's a detailed summary:

**Advantages:**
*   **Logical Organization:** Memory is organized in a way that matches the program's structure, making it easier for programmers and compilers to manage.
*   **Protection:** Segments can be assigned permissions (e.g., code segment is execute-only, data segment is read-write). An attempt to write to a code segment would generate a protection fault, enhancing security and stability.
*   **Isolation:** Different processes can have their own segments, preventing one program from interfering with another.

**Critical Limitations:**
*   **External Fragmentation:** Because segments are variable-sized, free memory becomes fragmented into many small, non-contiguous blocks over time. It becomes impossible to load a large segment, even if the total free memory is sufficient, because no single free block is large enough. This requires complex and slow **memory compaction** algorithms.
*   **Inefficient Memory Use:** A segment must be loaded contiguously into physical memory as a single unit, which is a strict requirement that leads to the fragmentation problem.

The problem of **external fragmentation** was a major driver for the development of a more flexible memory management scheme: **Paging**.

## The Global Descriptor Table (GDT)

The Global Descriptor Table (GDT) is the fundamental data structure that makes protected-mode segmentation possible on x86 architectures. It is essentially an array of **segment descriptors** that the CPU uses to define the characteristics of every segment in the system.

### What is a Segment Descriptor?

A segment descriptor is an 8-byte data structure that describes a single segment. It contains all the information the CPU needs to manage and control access to that segment. The key fields in a descriptor include:

*   **Base Address:** The 32-bit linear starting address of the segment in memory.
*   **Segment Limit:** The 20-bit size of the segment (either in bytes or in 4KB pages).
*   **Type:** What kind of segment it is (e.g., Code, Data, Stack) and its access permissions (e.g., Read/Write, Execute-Only).
*   **Privilege Level (DPL):** The Descriptor Privilege Level (0-3), where 0 is the most privileged (kernel) and 3 is the least privileged (user applications). This determines which privilege levels can access this segment.
*   **Segment Present Flag:** Indicates if the segment is currently loaded in memory.
*   **Granularity Flag:** If set, the segment limit is interpreted in 4KB units instead of bytes, allowing segments to be up to 4GB in size.

### How the GDT Works with Segmentation:

1.  **System Setup:** The operating system kernel, during boot-up, creates the GDT in memory and loads its address and size into the special **GDTR (GDT Register)** using the `LGDT` assembly instruction.
2.  **Segment Registers as Selectors:** In protected mode, the segment registers (`CS`, `DS`, `SS`, etc.) no longer hold a base address directly. Instead, they hold a **segment selector**.
3.  **The Selector's Role:** A selector is a 16-bit value that acts as an index into the GDT.
    *   **Index (Bits 3-15):** Specifies which entry (descriptor) in the GDT to use.
    *   **Table Indicator (TI, Bit 2):** If 0, use the GDT. If 1, use a Local Descriptor Table (LDT) for per-process segments.
    *   **Requested Privilege Level (RPL, Bits 0-1):** The privilege level of the current operation.
4.  **Address Translation via the GDT:**
    1.  The CPU takes the selector from a segment register (e.g., `CS`).
    2.  It uses the `TI` bit to choose the GDT (or LDT).
    3.  It uses the `Index` to find the corresponding 8-byte segment descriptor in the GDT.
    4.  It performs security checks (e.g., is the segment present? does the current privilege level have access?).
    5.  If checks pass, the CPU loads the **base address** and **limit** from the descriptor into an invisible, internal cache associated with the segment register.
    6.  For subsequent memory accesses, the CPU uses this cached base address, adding the instruction's offset to generate a **linear address**.

### Purpose and Importance:

*   **Centralized Management:** The GDT provides the OS with a single, secure table to define all memory segments available to the system.
*   **Hardware Enforcement:** The CPU hardware consults the GDT on every memory access, enforcing the protection rules defined by the OS. This prevents user applications from accessing kernel memory or executing data as code.
*   **Privilege Separation:** The DPL field is crucial for implementing the separation between kernel mode (ring 0) and user mode (ring 3).

>[!IMPORTANT]
> In modern OSes that use *paging* as the primary memory management mechanism, the GDT is still present but is often used in a "minimal" or "flat" configuration. Segments are configured to span the entire 4GB (or more) address space with a base of 0, effectively bypassing segmentation's memory splitting function. 
>
> However, the GDT's role in enforcing privilege levels (kernel vs. user) remains critical for system security and stability.

## A Conceptual Introduction to Paging

Paging is a memory management scheme that fundamentally decouples a program's view of memory from the actual physical hardware (RAM). Its primary goal is to solve the critical flaw of segmentation: **external fragmentation**.

### The Core Concept:

Instead of requiring that a program's code and data be stored in contiguous blocks of physical RAM (as segmentation does), paging introduces a powerful layer of **indirection**.

1. **Divide Memory into Fixed-Size Blocks:**
    *   **Physical Memory** is divided into equal-sized chunks called **frames**.
    *   A program's address space is divided into chunks of the same size, called **pages**.

2.  **The Indirection Map:**
    *   The kernel manages a **page table** for each process. This table is a map that translates the program's **page numbers** into the physical **frame numbers** where those pages are actually stored. 
    * This mapping is often called the **Page Map Table (PMT)** or simply the **page table**.

>[!IMPORTANT]
> The kernel itself **is also a program**, so it has its own page table. The key difference is that the kernel also manages the page tables of all other processes.

The key insight is that **any page can be placed into any available frame**. Because all pages and frames are the same size, the problem of external fragmentation is completely eliminated. There is no need to find a contiguous block of memory for a large segment; the OS can simply find any free frames, wherever they are located.

### Intutive Breakdown

Are you confused? Don't be! It’s really simple! **Paging just introduces a table of mappings.** That's it!

A program has **pages** (fixed size), which correspond to **physical frames** (also the same size as pages, but to differentiate, we call them frames) — and these frames can be scattered anywhere in physical memory.

To better understand it, think about this: In segmentation, all the program’s instructions would have to reside in a contiguous `.text` section in physical memory.

With paging, they can be scattered *anywhere* across physical memory (wherever there’s a free **frame**). The **Page Map Table (PMT)** maps these scattered frames into continuous **pages** that the program sees. So to the program, the code still appears as a single, continuous `.text` section, despite it being scattered all throughout physical memory in reality! 

When it accesses a page (for example, to execute some code), the PMT simply translates it to the corresponding physical frame. That’s it!

**Example:**

Suppose a program has 4 pages, and its page table looks like this:

| Page | Frame (Physical Memory) |
| ---- | ------------------------- |
| 0    | 5                         |
| 1    | 2                         |
| 2    | 8                         |
| 3    | 1                         |

If the program accesses **page 2**, the PMT translates it to **frame 8**, and the system reads from that physical memory location. The program still sees its memory as one continuous block through pages, even though the corresponding physical memory frames are scattered.

>[!IMPORTANT]
> What we’ve been intuitively calling the program’s *pages* are, in practice, referred to as *virtual pages*.

## Virtual Pages

This layer of indirection creates a powerful abstraction. A program does not work with physical addresses anymore. Instead, it operates within a **Virtual Address Space**.

*   Each process believes it has its own private, large, and contiguous memory space, starting at address 0. This is its virtual address space.
*   The addresses a program uses are called **virtual addresses**.
*   The chunks that make up this virtual address space are called **virtual pages**.

**Why are they called "Virtual" Pages?**
They are "virtual" because they are not tied to a fixed location in physical RAM. A virtual page might be:
*   Located in any physical frame.
*   Swapped out to disk (not in RAM at all!).
*   Shared with another process, so the same physical frame is mapped into two different virtual address spaces.
*   Not even allocated until the program first tries to use it (demand paging).

The virtual page is a placeholder, a unit of management within the program's illusory memory world. The page table (PMT) is what connects this virtual world to the physical reality of RAM.

## How Paging Works: A High-Level View

The translation from a virtual address (used by the program) to a physical address (used by the RAM) is performed automatically and transparently by the CPU's **Memory Management Unit (MMU)**.

### The Translation Process Step-by-Step:

1. **CPU Generates a Virtual Address:** The running program attempts to access a memory location, say `0x4000`. This is a virtual address.

2. **MMU Splits the Address:** The MMU splits the virtual address into two parts:
    *   **Virtual Page Number (VPN):** The high-order bits of the address. This identifies which page the address belongs to.
    *   **Page Offset:** The low-order bits of the address. This identifies the specific byte within the page.

    ```
    Virtual Address:  [ Virtual Page Number (VPN) | Page Offset ]
    ```

3. **Consult the Page Table:** The MMU uses the **VPN** as an index into the current process's page table. Each entry in the page table, called a **Page Table Entry (PTE)**, contains the **Physical Frame Number (PFN)** where that virtual page is located, along with control bits (Present, Read/Write, etc.).

>[!WARNING]
> **This is a simplified, high-level overview of how page table translation works.** In reality, the process is more complex and often involves 3, 4, or even 5 levels of page tables. We’ll explore these details later in this document.

4. **Check Permissions and Presence:** The MMU checks the PTE's control bits.
    * If the page is not allowed to be written to but the operation is a write, it triggers a segmentation fault.
    * If the **Present Bit** is 0, the page is not in RAM (it's on disk). This triggers a **page fault**, forcing the OS to load the page from disk into a free frame.

5. **Form the Physical Address:** If all checks pass, the MMU takes the **PFN** from the PTE and combines it with the original **page offset** to form the final physical address.

    ```
    Physical Address: [ Physical Frame Number (PFN) | Page Offset ]
    ```

This entire process happens for every memory access, and is heavily optimized by hardware (e.g., with a **Translation Lookaside Buffer (TLB)**, which is a cache for recent page table translations).

>[!IMPORTANT]
> The TLB is a hardware component inside the CPU, so our kernel doesn’t implement it or manage it. That said, we can still *interact* with it — for example, by flushing it when needed.

## What is Virtual Memory?

**Virtual Memory** is the overarching abstraction and technique that is implemented using **paging** (and to a lesser extent, segmentation). It is the illusion provided to each process that it has its own large, private, and contiguous address space, which may be larger than the actual physical RAM available.

Virtual Memory is not a single thing, but a combination of concepts and mechanisms:

1.  **The Illusion of a Private Address Space:** Each process operates as if it has exclusive use of the main memory, simplifying programming and ensuring isolation.

2.  **Paging as the Primary Mechanism:** Paging provides the core translation mechanism that makes this illusion possible by mapping virtual pages to physical frames.

3.  **Demand Paging:** This is a crucial aspect of Virtual Memory. Pages are only loaded into physical memory when the program actually accesses them (a "page fault" occurs). This allows programs to have virtual address spaces much larger than physical RAM. The rest of the program can reside on disk.

4.  **Swap Space:** The area on the disk (a file or partition) used to store pages that are not currently active in RAM. When physical memory fills up, the OS can "swap out" infrequently used pages to disk to free up frames, and "swap them in" later when needed.

### Tying It All Together

Think of the hierarchy:

*   **Physical Memory (RAM):** The real, finite hardware resource.
*   **Paging:** The *mechanism* that manages physical memory by breaking it into frames and mapping them to virtual pages.
*   **Virtual Pages:** The units of the illusory memory space that programs use.
*   **Virtual Memory:** The final *abstraction* presented to the process, enabled by the paging mechanism. It encompasses the entire system, including the use of disk storage to extend the available "memory."

In modern operating systems, when we talk about a process's memory, we are almost always referring to its **virtual memory**. The complex work of translating virtual addresses to physical addresses and shuffling pages between RAM and disk is handled automatically by the OS and MMU, completely hidden from the application.

## Paging in 32-bit protected mode

Paging in a 32-bit kernel is optional. If enabled, it consists of **2 levels of page tables** that work together to translate virtual addresses to physical addresses. This hierarchical structure efficiently manages the 4 GB virtual address space (2^32 bytes) that 32-bit systems can address.

### The Two-Level Hierarchy:

| Table Level | Entries | Entry Size | Purpose | Controls |
|-------------|---------|------------|---------|----------|
| **Page Directory (PD)** | 1,024 | 4 bytes | Top-level table; each entry points to a Page Table | 4 MB region of virtual space per entry |
| **Page Table (PT)** | 1,024 | 4 bytes | Second-level table; each entry points to a physical page frame | 4 KB page of physical memory |

**Why 1,024 entries?** Each table is 4KB in size (because it must fit within a single 4KB page). Since each entry is 4 bytes (32 bits), we get 4,096 ÷ 4 = **1,024 entries per table**.

### Memory Coverage Explained:

* **PT Entry:** Points to a **4 KB physical page frame**. With 1,024 entries, one Page Table maps 1,024 × 4 KB = **4 MB** of virtual memory.
* **PD Entry:** Points to an entire PT, which in turn maps 4 MB. With 1,024 entries, one Page Directory can map 1,024 × 4 MB = **4 GB** of virtual memory (the entire 32-bit address space).

### Virtual Address Translation:

A 32-bit virtual address is split into three parts by the hardware Memory Management Unit (MMU):

* **Directory Index (10 bits):** Selects which entry in the PD to use (2^10 = 1,024 possibilities). This entry points to the target PT.
* **Table Index (10 bits):** Selects which entry in the target PT to use (2^10 = 1,024 possibilities). This entry points to the physical frame.
* **Offset (12 bits):** Locates the specific byte within the 4 KB physical page frame (2^12 = 4,096 bytes).


### Control Registers and Enabling Paging:

Paging is controlled by the **CR0** and **CR3** control registers.

*   **CR3 (Page Directory Base Register):** This register must be loaded with the *physical* address of the current process's PD (highest level page table). The CPU uses this as the starting point for all translations.
*   **CR0 (Control Register 0):** Bit 31 (the PG bit) is the master switch. Setting this bit to 1 globally enables the paging mechanism on the processor.

**To enable paging, the kernel must:**
1. **Identity map** the necessary code and data structures (so instructions can continue to execute after the switch).
2. Configure at least one PD and its corresponding PTs for the identity map.
3. Load the physical address of the Page Directory into the `CR3` register.
4. Set the PG bit in `CR0`. The moment this bit is set, the MMU immediately begins using the page tables for all subsequent memory accesses.

>[!NOTE]
> We will talk about what the *identity map* is later on in this document.

### Example:

Let's translate virtual address `0x00402010`:

1.  **Split the address:** 
    - Directory Index: `0x001` (bits 22-31)
    - Table Index: `0x004` (bits 12-21)  
    - Offset: `0x010` (bits 0-11)

2.  **Translation steps:**
    - CPU reads CR3 to find Page Directory physical address
    - Uses index `0x001` to find PDE #1
    - PDE #1 points to physical address of Page Table #1
    - Uses index `0x004` to find PTE #4 in that table
    - PTE #4 contains physical frame address (e.g., `0x0000C000`)
    - Final physical address: `0x0000C000 + 0x010 = 0x0000C010`

This shows how the seemingly contiguous virtual address `0x00402010` actually maps to a completely different, non-contiguous physical location.

## Paging in 64-bit Long Mode

Paging in a 64-bit kernel is mandatory and consists of **4 levels of page tables** that work together to translate virtual addresses to physical addresses. This hierarchical structure manages the massive 256 TB virtual address space (2^48 bytes) that 64-bit systems typically implement, though the architecture supports up to 2^64 bytes.

>[!NOTE]
> Only the lower 48 bits of the virtual address are currently used. The remaining upper bits (bits 48–63) must be copies of bit 47 — either all 0s or all 1s — to ensure a canonical address. Accessing a non-canonical address will cause a CPU exception.

### The Four-Level Hierarchy:

| Table Level | Entries | Entry Size | Purpose | Controls |
|-------------|---------|------------|---------|----------|
| **Page Map Level 4 (PML4)** | 512 | 8 bytes | Top-level table; each entry points to a Page Directory Pointer Table | 512 GB region of virtual space per entry |
| **Page Directory Pointer Table (PDPT)** | 512 | 8 bytes | Second-level table; each entry points to a Page Directory | 1 GB region of virtual space per entry |
| **Page Directory (PD)** | 512 | 8 bytes | Third-level table; each entry points to a Page Table | 2 MB region of virtual space per entry |
| **Page Table (PT)** | 512 | 8 bytes | Bottom-level table; each entry points to a physical page frame | 4 KB page of physical memory |

**Why 512 entries?** Each table must fit within a single 4 KB page (4,096 bytes). Since each entry is 8 bytes (64 bits), we get 4,096 ÷ 8 = **512 entries per table**.

### Memory Coverage Explained:

* **PT Entry:** Points to a **4 KB physical page frame**. With 512 entries, one PT maps 512 × 4 KB = **2 MB** of virtual memory.
* **PD Entry:** Points to an entire PT, which in turn maps 2 MB. With 512 entries, one PD can map 512 × 2 MB = **1 GB** of virtual memory.
* **PDPT Entry:** Points to an entire PD, which in turn maps 1 GB. With 512 entries, one PDPT can map 512 × 1 GB = **512 GB** of virtual memory.
* **PML4 Entry:** Points to an entire PDPT, which in turn maps 512 GB. With 512 entries, one PML4 can map 512 × 512 GB = **256 TB** of virtual memory.

### Virtual Address Translation:

A 64-bit virtual address (though typically only 48 bits are used) is split into five parts by the hardware Memory Management Unit (MMU):

* **PML4 Index (9 bits):** Selects which entry in the PML4 to use (2^9 = 512 possibilities). This entry points to the target PDPT.
* **PDPT Index (9 bits):** Selects which entry in the PDPT to use (2^9 = 512 possibilities). This entry points to the target PD.
* **PD Index (9 bits):** Selects which entry in the PD to use (2^9 = 512 possibilities). This entry points to the target PT.
* **PT Index (9 bits):** Selects which entry in the PT to use (2^9 = 512 possibilities). This entry points to the physical frame.
* **Offset (12 bits):** Locates the specific byte within the 4 KB physical page frame (2^12 = 4,096 bytes).

The translation works as a four-step lookup:
1. The CPU uses the **PML4 Index** to find the correct PML4 Entry, which points to a PDPT.
2. The CPU uses the **PDPT Index** to find the correct PDPT Entry, which points to a PD.
3. The CPU uses the **PD Index** to find the correct PD Entry, which points to a PT.
4. The CPU uses the **PT Index** to find the correct PT Entry, which contains the physical frame address.
5. The CPU combines this physical frame address with the 12-bit **Offset** to generate the final physical address.

### Control Registers and Enabling Paging:

Paging in 64-bit mode is controlled by the same **CR0** and **CR3** control registers, but with additional model-specific registers (MSRs).

* **CR3 (Page Directory Base Register):** This register contains the *physical* address of the current process's PML4 (highest level page table). The CPU uses this as the starting point for all translations.
* **CR0 (Control Register 0):** Bit 31 (the PG bit) must be set to enable paging.
* **EFER MSR:** The Long Mode Enable (LME) bit must be set along with PG to activate 64-bit paging.

**To enable 64-bit paging, the kernel must:**
1. **Identity map** the necessary code and data structures for the initial transition.
2. Configure at least one PML4 and its corresponding PDPs, PDs, and PTs for the identity map.
3. Load the physical address of the PML4 into the `CR3` register.
4. Set the PG bit in `CR0` and the LME bit in the EFER MSR to activate 64-bit paging mode.

### Example

Let's translate the Virtual Address `0x00007FFF00402010`

1. **Split the address:**

   * PML4 Index: `0x0FF` (bits 39–47)
   * PDPT Index: `0x1FC` (bits 30–38)
   * PD Index: `0x002` (bits 21–29)
   * PT Index: `0x002` (bits 12–20)
   * Offset: `0x010` (bits 0–11)

2. **Translation steps:**

* **Step 1:** CPU reads `CR3` to get the physical address of the **PML4 table**.

  * Uses **PML4 Index `0x0FF`** (Entry #255) to select the PML4 entry.
  * This entry points to the physical address of the **PDPT table**.

* **Step 2:** Access the **PDPT table**.

  * Uses **PDPT Index `0x1FC`** (Entry #508) to select the PDPT entry.
  * This entry points to the physical address of the **Page Directory (PD)**.

* **Step 3:** Access the **Page Directory**.

  * Uses **PD Index `0x002`** (Entry #2) to select the PD entry.
  * This entry points to the physical address of the **Page Table (PT)**.

* **Step 4:** Access the **Page Table**.

  * Uses **PT Index `0x002`** (Entry #2) to select the PT entry.
  * This entry contains the **physical frame address** (e.g., `0x0000C000`).

* **Step 5:** Combine the physical frame with the **offset `0x010`** to get the **final physical address**:

  * `0x0000C000 + 0x010 = 0x0000C010`.

This demonstrates how **64-bit paging adds two extra levels** (PML4 and PDPT) to handle the vastly larger address space, while still using the same 4 KB page size.

## The Identity Mapping

>[!WARNING]
>*This section is not yet ready. Please check it out tomorrow!*

## A Higher Half Kernel

>[!WARNING]
>*This section is not yet ready. Please check it out tomorrow!*